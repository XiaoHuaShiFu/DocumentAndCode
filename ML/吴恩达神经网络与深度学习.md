# 2、神经网络基础

1. 二分分类

   - Notation

     ![image-20200408204705412](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200408204705412.png)

2. logistic regression cost function

   ![image-20200408211022280](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200408211022280.png)

3. 梯度下降

   ![image-20200409005017750](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200409005017750.png)

4. 向量化

   1. ![image-20200409010332010](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200409010332010.png)
   2. ![image-20200409011446703](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200409011446703.png)
   3. ![image-20200409012352294](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200409012352294.png)
   4. ![image-20200409012844343](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200409012844343.png)

# 3、浅层神经网络

1. 逐层拆解

   ![image-20200410005401897](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200410005401897.png)

2. vectorizing across multiple examples

   ![image-20200410010558779](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200410010558779.png)

   

3. Activation function：激活函数均值接近0比较好

   - ![image-20200410011912098](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200410011912098.png)

   - tanh：均值为0，[-1, 1]
     - 几乎都比sigmoid函数好。除了在输出层外，因为如果希望输出是0~1，sigmoid可以把输出值调整到0~1，在二元分类的时候可以使用sigmoid作为输出层的激活函数。
   - **默认规则：除了二元分类用sigmoid作为输出层的激活函数外，都用Relu。**
   - 如果用线性激活函数，那么不管经过多少层，都还是输出线性函数，因此无法拟合复杂的情况。**除了在输出层需要把输出转换成线性的函数（-∞，+∞）。**

4. Summary of gradient descent：也是可以向量化的

   ![image-20200410015618019](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200410015618019.png)

5. random initialization：要乘一个很小的数，这样开始训练的时候才会快。因为sigmoid在值大的时候斜率很小。

   ![image-20200410020819588](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200410020819588.png)

# 4、深层神经网络

1. 通过图解释深层神经网络计算过程

   ![image-20200410202010199](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200410202010199.png)

   ![image-20200410202357922](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200410202357922.png)

   ![image-20200410203037103](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200410203037103.png)

2. 矩阵的维数

   1. W，b，dW，db

      ![image-20200410205107174](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200410205107174.png)

   2. Z、A、dZ、dA

      ![image-20200410205233681](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200410205233681.png)

3. hyperparameters

   1. ![image-20200411021637959](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411021637959.png)
   
4. ![GALBOL](https://img-blog.csdn.net/20180331114317342?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM3MzMzMjY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

# 5、Setting up your ML application

1. Train/dev/test sets

   - 比例可以是6 2 2 ，或者98 1 1（大数据），或者99 0.5 0.5（更大数据）
   - ![image-20200411025240143](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411025240143.png)

2.  Bias/Variance

   - ![image-20200411030617560](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411030617560.png)

   - ![image-20200411031221324](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411031221324.png)

   - regularization：解决高方差问题，避免过度拟合，weight decay 权重衰减。有L2和Dropout

     - 在神经网络中，会使得一些节点影响较小，避免过拟合。

     - L2正则化参数大，W小，Z也小，这样激活函数更容易呈现线性

       ![image-20200411033440673](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411033440673.png)

     - Dropout regularization：随机去节点

       - ![image-20200411033733291](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411033733291.png)

       - implementing dropout

         ![image-20200411174044710](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411174044710.png)

       - 在测试阶段不适用dropout

       - why does dropout work

         ![image-20200411173937740](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411173937740.png)

     - data augmentation：也是一种正则化方法，因为可以添加样本的数量，这样样本会考虑更多的因素

       ![image-20200411174315216](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411174315216.png)

     - early stopping：使得不会一直拟合到过拟合

       ![image-20200411174404485](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411174404485.png)

3. normalizing inputs

   - 加速训练![image-20200411174552707](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411174552707.png)
   - ![image-20200411174635547](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411174635547.png)

4. vanishing/exploding gradients

   - ![image-20200411174714729](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411174714729.png)

   - Weight initialization：添加一个参数，使得Z的均值接近1，避免梯度消失or爆炸

     ![image-20200411174903245](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411174903245.png)

5. gradient checking

   - 也就是检查梯度下降是不是正确的

     ![image-20200411175044590](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411175044590.png)

   - 梯度检查的一些要主要的点

     ![image-20200411175111717](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411175111717.png)

# 6、优化算法

1. mini-batch gradient descent：分小组进行计算，加速计算

   - ![image-20200411175145789](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411175145789.png)

   - cost function会有噪音

     ![image-20200411175206941](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411175206941.png)

   - mini-batch size 要合适

     ![image-20200411175226994](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411175226994.png)

2. Bias correction in exponentially weighted average：有一定的缓冲作用，避免突然梯度加速太快

   - Momentum![image-20200411175524041](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411175524041.png)
   - ![image-20200411175535106](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411175535106.png)

3. RMSprop：也是修正作用，慢的加速，快的减速

   ![image-20200411184835218](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411184835218.png)

4. Adam optimization algorithm：同时使用momentum和RMSprop

   - ![image-20200411184924084](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411184924084.png)

5. Learning rate decay：随着次数自动减小学习率

   - ![image-20200411190030444](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411190030444.png)

   - 其他learning rate decay methods

     ![image-20200411190106122](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411190106122.png)

6. The problem of local optima

   - Adam这样的算法可以加速越过鞍点![image-20200411190649738](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411190649738.png)

# 8、Hyperparameter tuning

1. Tuning process

   - <img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411192140778.png" alt="image-20200411192140778" style="zoom:33%;" />

   - Coarse to fine:随机取值，训练，减小搜素范围![image-20200411192634439](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411192634439.png)

   - Learning rate：用指数，然后随机选取范围内的指数，作为学习率

     ![image-20200411193427812](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411193427812.png)

   - exponentially weighted averages：在接近1的时候，比如0.9995 到0.9996，这时候变化会很快

     ![image-20200411193908525](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411193908525.png)

   - 调参的两种学派：

     ![image-20200411194627334](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411194627334.png)

2. Normalizing activations in a network：对隐藏层是Z进行Normalizing，两个参数是用来调节Z的范围的

   ![image-20200411195842962](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411195842962.png)

   - 这两个参数也要进行梯度下降

     ![image-20200411200558403](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411200558403.png)

   - Working with mini-batches：这两个参数会使得参数b失效，因此可以去掉参数b。不过参数β是对参数b的一种补充。

   - implementing gradient descent

     ![image-20200411201649632](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411201649632.png)

   - 不但加速学习，而且可以使得均值和方差为0和1，这样即使训练集不那么全面，也不会造成预测的结果相差很大。其实也就是限制前面层的参数更新，使得后面层学习得更加稳定。batch归一化减小了输入值改变的问题。也是减小了前层参数与后层参数的联系，使得每一层更加独立。

   - 而且它在前面层添加了噪音，这样就使得后面层不可以依赖某个前面层的节点，也是regularization的一种。

     ![image-20200411205530841](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411205530841.png)

   - Batch Norm at test time：要在训练时进行exponentially weighted average计算两个参数

     ![image-20200411210206382](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411210206382.png)

3. Softmax regression回归

   1. 概率映射![image-20200411211323915](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411211323915.png)

   2. a generalization of logistic regression

      ![image-20200411211625708](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411211625708.png)

   3. 然后用hard max函数映射成 [1 0 0 0]这样的形式

   4. loss function

      ![image-20200411212048232](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411212048232.png)

      ![image-20200411212223815](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200411212223815.png)

# 9、Convolutional Neural Networks

1. Edge detection

   1. Vertical edge detection

      - Convolutional compute： tf.nn.conv2d, keras.Conv2D
      - ![image-20200412154042870](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412154042870.png)

   2. Horizontal Edge Detection

      ![image-20200412154541170](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412154541170.png)

   3. Learning to detect edges

      ![image-20200412155154831](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412155154831.png)

2.  Padding

   ![image-20200412160208171](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412160208171.png)

   - Valid and Same convolutions：一种是不填充，一种是填充后使得和原图像长度一样。filter一般是奇数长度。这里的**超参数是p**。

     ![image-20200412160616367](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412160616367.png)

3. Stided convolutions：**超参数s**。

   - ![image-20200412161241557](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412161241557.png)

4. Vonvolutions over volumes

   1. ![image-20200412162433422](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412162433422.png)

   2. multiple filters

      ![image-20200412162743546](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412162743546.png)

5. One layer of a convolutional network

   1. ![image-20200412165203168](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412165203168.png)

   2. Summary of notation

      ![image-20200412170712091](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412170712091.png)

   3. Example ConvNet：nc不断增加，nH和nW不断减小，开始进行卷积运算，然后展开进行普通的神经网络计算。

      - ![image-20200412172432233](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412172432233.png)

   4. Types of layer in a convolutional network：

      ![image-20200412172714112](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412172714112.png)

6. Pooling layers：使得特征更加明显，加快计算

   - Max pooling

     ![image-20200412173443628](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412173443628.png)

   - Average pooling

     ![image-20200412173601483](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412173601483.png)

   - Pooling parameters

     ![image-20200412173821620](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412173821620.png)

7. Convolutional neutral network example

   - 手写数字识别![image-20200412175313833](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412175313833.png)

   - 网络参数

     ![image-20200412175615851](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412175615851.png)

8. Why convolutions

   - 两个原因：![image-20200412191140489](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412191140489.png)

# 10、Case Studies

1. Classic neural network

   1. LeNet-5：数字识别

      ![image-20200412214433584](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412214433584.png)

   2. AlexNet：大型图像识别网络

      ![image-20200412215431930](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412215431930.png)

   3. VGG-16：更大型的图像识别网络

      ![image-20200412220037671](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412220037671.png)

2. Residual Networks （ResNets）

   1. 把al插入到后面的层的线性函数之后激活函数之前

   2. 可以避免深层网络训练误差上升，和梯度消失，梯度爆炸等问题

      ![image-20200412221647913](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412221647913.png)

   3. Why do residual networks work？因为会使得网络学习恒等函数，这样学习起来很容易。而且中间层也会保留，这样至少比plain netwroks好。如果al+2和al的维度不同，可以通过参数矩阵ws调整al的维度。

      ![image-20200412222842933](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412222842933.png)

   4.  ResNet和PlainNet

      ![image-20200412223053683](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412223053683.png)

3. Network in Network and 1x1 convolutions

   1. 作用是：对通道数长度的单元进行一次全连接运算，使得输出和1x1过滤器数量相同的通道数。比如6x6x32进行1x1x32的三个过滤器（convolution），会变成6x6x3的形状。

      ![image-20200412223856334](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412223856334.png)

   2. Inception network motivation 

      - 让网络自己选择卷积核池化层

        ![image-20200412224645946](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412224645946.png)

      - 可以用1x1convolution减少计算量

        ![image-20200412225451141](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412225451141.png)

      - Inception module

        ![image-20200412230009140](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412230009140.png)

      - Inception network

        ![image-20200412230345751](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412230345751.png)

4. Using open-source implementations：从Github上下载别人实现好的。

5. Transfer Learning

   1. freeze部分不需要训练，只需要训练softmax部分进行分类。‘

      ![image-20200412234832854](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412234832854.png)

6. Data augmentation

   1. Mirroring和Random Cropping

      ![image-20200412235351528](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412235351528.png)

   2. Color shifting：鲁棒性，可以使用PCA color augmentation

      ![image-20200412235754350](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200412235754350.png)

   3. Implementing distortions during training

      ![image-20200413000204903](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200413000204903.png)

7. Data vs. hand-engineering

   ![image-20200413001238971](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200413001238971.png)

8. Tips for doing well on benchmarks/winning competitions：训练多个网络，然后选最好的；训练多种格式的图片，然后选最好的。都是为了比赛或者发论文。

   ![image-20200413001752456](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200413001752456.png)

9. 实际生产的推荐做法

   ![image-20200413001951669](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200413001951669.png)


# 11、Object Detection

1. object localization

   - What are localization and detection？

     ![image-20200413211352616](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200413211352616.png)

   - ![image-20200413211824142](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200413211824142.png)

   - ![image-20200413212638194](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200413212638194.png)

2. Object detection

   1. Car detection：先训练检测车的模型

      ![image-20200413235731445](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200413235731445.png)

   2. Sliding windows detection：计算量太大

      ![image-20200414001843371](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414001843371.png)

3. Convolutional implementation of sliding windows

   1. Turning FC layer into convolutional layers

      ![image-20200414004111381](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414004111381.png)

   2. Convolution implementation of sliding windows

      ![image-20200414005625167](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414005625167.png)

4. Bounding Box预测

   1. YOLO：对预测算法进行训练的时候，就用整张图片。先切割，然后训练。

      ![image-20200414014552329](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414014552329.png)

   2. Specify the bounding boxes

      ![image-20200414014901865](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414014901865.png)

5. Intersection over union：交并比，判断预测的好坏

   1. Evaluating object localization

      ![image-20200414015626275](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414015626275.png)

6. Non-max suppression：会有多于实际的格子表示有车。

   1. ![image-20200414020224941](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414020224941.png)
   2. ![image-20200414020618150](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414020618150.png)

7. Anchor boxes

   1. Overlapping objects：to detect the overlapping objects

      ![image-20200414021411780](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414021411780.png)

   2. ![image-20200414021710506](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414021710506.png)

   3. ![image-20200414021858653](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414021858653.png)

8. YOLO algorithm

   1. Making predictions

      ![image-20200414022521175](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414022521175.png)

   2. Outputting the non-max supressed outputs

      ![image-20200414022706347](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414022706347.png)

9. Region proposal:R-CNN

   1. R-CNN：先挑取概率大的，然后再精确计算

# 12、Application

1. Face verification vs. face recognition

   ![image-20200414134450413](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414134450413.png)

2. One-shot learning

   1. Learning a "similarity" function

      ![image-20200414135146048](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414135146048.png)

   2. Siamese netwrok

      - ![image-20200414135616500](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414135616500.png)
      - ![image-20200414135725771](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414135725771.png)

   3. Triplet loss

      - Learning Objection

        ![image-20200414140411395](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414140411395.png)

      - Loss function

        ![image-20200414140853519](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414140853519.png)

      - Choosing the triplets APN

         ![image-20200414141141030](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414141141030.png)

3. Face verification and binary classification

   1. Learning the similarity function：当成二分类问题，可以提前训练f(x)，不需要存储图片

      ![image-20200414142244662](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414142244662.png)

4. Neural Style Transfer

   1. ![image-20200414142729816](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414142729816.png)

   2. Cost function

      ![image-20200414144112337](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414144112337.png)

   3. Find the generated image G

      ![image-20200414144245941](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414144245941.png)

   4. Content cost function

      ![image-20200414144706490](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414144706490.png)

   5. Style cost function

      1. ![image-20200414145432948](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414145432948.png)

      2. Style matrix

         ![image-20200414145747537](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414145747537.png)

      3. ![image-20200414150436813](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414150436813.png)

      4. Style cost function

         ![image-20200414150716519](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414150716519.png)

# 13、Sequence model

1. Some Examples of Sequence data

   ![image-20200414162128421](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414162128421.png)

2. Notation

   1. Motivating example

      ![image-20200414163232294](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414163232294.png)

   2. Representing words：use one-hot encoding

      ![image-20200414163944478](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414163944478.png)

   

3. Recurrent Neural Networks

   1. ![image-20200414165452765](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414165452765.png)

   2. Forward Propagation

      ![image-20200414165857044](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414165857044.png)

   3. Simplified RNN notation

      ![image-20200414170354054](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414170354054.png)

4. Backpropagation through time

   1.  ![image-20200414171539427](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414171539427.png)

5. Different types of RNNs

   1. many to many、 mana to one、 one to one

      ![image-20200414172115986](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414172115986.png)

   2. one to many、many to many with different length

      ![image-20200414172448858](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414172448858.png)

   3. summary

      ![image-20200414172531204](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414172531204.png)

6. Language model and sequence generation

   1. Language modelling with an RNN

      ![image-20200414185210177](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414185210177.png)

   2. RNN model

      ![image-20200414190008591](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414190008591.png)

7. Sampling a sequence from a trained RNN：生成随机句子。

   - ![image-20200414190642903](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414190642903.png)

   - Character-level language model：基于字符的网络模型

     ![image-20200414191017447](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414191017447.png)

8. Vanishing gradients with RNNs

   1. 后面的层难以影响前面的层，这在语言中是不太行的。

      ![image-20200414194320901](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414194320901.png)

   2. Gated Recurrent Unit（GRU）

      - 也就记录某些值在神经细胞里，这样前面的就会影响到后面的。

        ![image-20200414200549476](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414200549476.png)

      - Full GRU

        ![image-20200414200932198](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414200932198.png)

9. LSTM(long short term memory) unit

   1. GRU and LSTM

      ![image-20200414211724582](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414211724582.png)

   2. ![image-20200414212546269](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414212546269.png)

10. Bidirectional RNN

    1. 添加了一个反向的网络

       ![image-20200414213444795](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414213444795.png)

11. Deep RNNs

    - ![image-20200414213951761](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200414213951761.png)

12.  梯度修剪
         在这里，我们将实现在优化循环中调用的clip函数。回想一下，整个循环结构通常包括前向传播、成本计算、反向传播和参数更新。在更新参数之前，我们将在需要时执行梯度修剪，以确保我们的梯度不是“爆炸”的。

         接下来我们将实现一个修剪函数，该函数输入一个梯度字典输出一个已经修剪过了的梯度。有很多的方法来修剪梯度，我们在这里使用一个比较简单的方法。梯度向量的每一个元素都被限制在[−N，N][-N，N][−N，N]的范围，通俗的说，有一个maxValue（比如10），如果梯度的任何值大于10，那么它将被设置为10，如果梯度的任何值小于-10，那么它将被设置为-10，如果它在-10与10之间，那么它将不变



# 14、NLP

1. Featurized  representation

   1. word embedding

      ![image-20200415142251818](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415142251818.png)

   2. Visualizing word embedding![image-20200415142407000](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415142407000.png)

   3. Transfer learning and word embeddings

      ![image-20200415150830982](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415150830982.png)

2. Properties of word embeddings

   1. **Cosine similarity：如果两个词特征相似，那么它们的特征向量也相似，因此cos的结果就大；如果完全相反，那么cos结果就是-1。这样就可以找到相似的词对，比如知道男女的向量，然后找到和国王的角度最接近男女的向量的那个点，就可以找到女王那个点。也就可以配对了。**

      ![image-20200415152636323](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415152636323.png)

3. Embedding matrix

   ![image-20200415153548848](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415153548848.png)

4. Learning word embeddings

   1. Neural language model：拿单词-》拿特征-》特征入神经网络-》输出预测结果

      ![image-20200415155054025](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415155054025.png)

   2. Word2Vec

      1. Skip-gram

         ![image-20200415160445224](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415160445224.png)

      2. 由于Softmax计算量太大，可以使用树状分类器

         ![image-20200415160807531](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415160807531.png)

   3. Negative sampling model

      1. ![image-20200415162402420](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415162402420.png)

   4. GloVe word vectors

      1.   ![image-20200415164031304](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415164031304.png)
      2. ![image-20200415163853371](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415163853371.png)
      3. 每个特征向量可能是几个特征一起学习的结果![image-20200415164351497](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415164351497.png)

5. Sentiment classification

   1. Sentiment classification problem

      ![image-20200415164800858](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415164800858.png)

   2. Simple sentiment classification model

      ![image-20200415165118820](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415165118820.png)

   3. RNN for sentiment classification

      ![image-20200415165252196](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415165252196.png)

6. Debiasing word embeddings：消除偏见

   ![image-20200415170441055](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415170441055.png)

# 15、

1. Sequence to sequence model

   1. ![image-20200415173359497](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415173359497.png)
   2. ![image-20200415173632936](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415173632936.png)

2. Picking the most likely sentence

   1. Machine tanslation as building a conditional language model

      ![image-20200415174102157](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415174102157.png)

   2. Greedy search：that is bad

       ![image-20200415184054225](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415184054225.png)

   3. Beam search

      1. ![image-20200415185125835](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415185125835.png)
      2. ![image-20200415185229733](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415185229733.png)

   4. Refinements to beam search

      1. Length normalization

         ![image-20200415191415716](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415191415716.png)

      2. Beam search discussion

         - large B： better result， slower
         - small B： worse result，faster

3. Error analysis on beam search

   1. Error analysis on beam search

      ![image-20200415193651213](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415193651213.png)

   2. Error analysis process

      ![image-20200415193927242](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415193927242.png)

4. Bleu score

   1. Evaluating machine translation

      ![image-20200415194942319](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415194942319.png)

   2. Bleu score on bigrams

      ![image-20200415195218034](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415195218034.png)

   3. Bleu details

      ![image-20200415195637599](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415195637599.png)

5. Attention model

   1. Attention model intuition

      ![image-20200415202354602](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415202354602.png)

   2. Attention model

      ![image-20200415204149159](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415204149159.png)

   3. Computing attention α

      ![image-20200415204816748](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415204816748.png)

   4. 可以用于日期格式化等

6. Speech recognition

   1. Attention model for speech recognition

      ![image-20200415205534649](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415205534649.png)

   2. CTC cost for speech recognition

      ![image-20200415205912668](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415205912668.png)

7. Trigger word detection

   1. ![image-20200415210616607](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200415210616607.png)

